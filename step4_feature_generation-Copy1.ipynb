{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "from implicit.nearest_neighbours import ItemItemRecommender, BM25Recommender, TFIDFRecommender, bm25_weight\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "RAW_DATA_PATH = './raw_data/'\n",
    "DATA_PATH = './data'\n",
    "RANDOM_STATE = 42\n",
    "TOP_N = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clicks = pd.read_hdf(os.path.join(DATA_PATH, 'step1_enriched_train_clicks.h5'), index=None, key='step1')\n",
    "train_likes = pd.read_hdf(os.path.join(DATA_PATH, 'step1_enriched_train_likes.h5'), index=None, key='step1')\n",
    "train_shares = pd.read_hdf(os.path.join(DATA_PATH, 'step1_enriched_train_shares.h5'), index=None, key='step1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_clicks = pd.read_hdf(os.path.join(DATA_PATH, 'step1_val_clicks.h5'), index=None, key='step1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users = pd.read_csv(os.path.join(RAW_DATA_PATH, 'test_users.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_PATH, 'val1_users.json'), 'r') as f:\n",
    "    val1_users = set(json.load(f)['users'])\n",
    "    \n",
    "with open(os.path.join(DATA_PATH, 'val2_users.json'), 'r') as f:\n",
    "    val2_users = set(json.load(f)['users'])\n",
    "    \n",
    "val_users = val1_users | val2_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mapping = pd.read_csv(os.path.join(DATA_PATH, 'step0_user_mapping.csv'))\n",
    "picture_mapping = pd.read_csv(os.path.join(DATA_PATH, 'step0_picture_mapping.csv'))\n",
    "\n",
    "user_mapping_dict = user_mapping.groupby('old')['new'].first().to_dict()\n",
    "picture_mapping_dict = picture_mapping.groupby('old')['new'].first().to_dict()\n",
    "inv_picture_mapping_dict = dict([(v, k)for k, v in picture_mapping_dict.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_candidates(val_users, candidates1, candidates2):\n",
    "    result = {}\n",
    "    for user_id in tqdm(val_users):\n",
    "        items1 = candidates1.get(user_id, [])\n",
    "        items2 = candidates2.get(user_id, [])\n",
    "        items = list(set(items1) | set(items2))\n",
    "        if len(items) > 0:\n",
    "            result[user_id] = items\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# als candidates\n",
    "def get_als_candidates(\n",
    "    val_users, \n",
    "    train_clicks,\n",
    "    als_model, \n",
    "    already_candidates,\n",
    "    N\n",
    "):\n",
    "    global user_mapping\n",
    "    global picture_mapping\n",
    "    global user_mapping_dict\n",
    "    global picture_mapping_dict\n",
    "    \n",
    "    selected_train_clics = train_clicks\n",
    "    user_ids = selected_train_clics['user_id'].map(user_mapping.set_index('old').new)\n",
    "    picture_ids = selected_train_clics['picture_id'].map(picture_mapping.set_index('old').new)\n",
    "\n",
    "    train_picture_user_clicks_matrix = sp.csr_matrix(\n",
    "        (np.tile(1, selected_train_clics.shape[0]),\n",
    "            (\n",
    "                picture_ids,\n",
    "                user_ids\n",
    "            )\n",
    "        ),\n",
    "        shape=(len(picture_mapping_dict) + 1, len(user_mapping_dict) + 1),\n",
    "        dtype=np.float\n",
    "    )\n",
    "    train_picture_user_clicks_matrix.shape\n",
    "    \n",
    "    # Prediction\n",
    "    val_pred_als = dict()\n",
    "    \n",
    "    for user_id in tqdm(list(val_users)):\n",
    "        user_index = user_mapping_dict[user_id]\n",
    "\n",
    "        if als_model.user_factors[user_index][0] == 0:\n",
    "            continue\n",
    "\n",
    "        _pred = als_model.recommend(\n",
    "            user_index, \n",
    "            train_picture_user_clicks_matrix.T, \n",
    "            N,\n",
    "            filter_already_liked_items=True,\n",
    "        )\n",
    "        _pred = [inv_picture_mapping_dict[x[0]] for x in _pred]\n",
    "        val_pred_als[user_id] = _pred\n",
    "\n",
    "#     filter_transactions = pd.concat([\n",
    "#         transactions.loc[:, ['user_uid', 'element_uid']],\n",
    "#     ]).query('user_uid in @val_users')\n",
    "\n",
    "#     filtered_elements = filter_transactions.groupby('user_uid')['element_uid'].agg(set).to_dict()\n",
    "    \n",
    "#     for user_uid in val_users:    \n",
    "#         filtered_elements[user_uid] = filtered_elements.get(user_uid, set())\n",
    "#         filtered_elements[user_uid] = filtered_elements[user_uid].union(already_candidates.get(user_uid, set()))\n",
    "    \n",
    "#     user_ids = transactions['user_uid'].map(user_mapping.set_index('old').new)\n",
    "\n",
    "#     ratings_matrix = sp.csr_matrix(\n",
    "#         (np.ones(len(transactions)),\n",
    "#             (\n",
    "#                 user_ids,\n",
    "#                 transactions['element_uid']\n",
    "#             )\n",
    "#         ),\n",
    "#         shape=(item_user_matrix_shape[1], item_user_matrix_shape[0])\n",
    "#     )\n",
    "\n",
    "#     user_uid_to_cat = user_mapping.set_index('old').new.to_dict()\n",
    "#     warm_users = set(transactions['user_uid'].unique())\n",
    "\n",
    "#     als_candidates = {}\n",
    "\n",
    "#     for user_uid in tqdm.tqdm(val_users):\n",
    "#         # transform user_uid to model's internal user category\n",
    "#         if user_uid not in warm_users:\n",
    "#             continue\n",
    "            \n",
    "#         user_cat = user_uid_to_cat[user_uid]\n",
    "\n",
    "#         # perform inference\n",
    "#         recs = model.recommend(\n",
    "#             user_cat,\n",
    "#             ratings_matrix,\n",
    "#             N=N,\n",
    "#             filter_already_liked_items=True,\n",
    "#             filter_items=filtered_elements.get(user_uid, set())\n",
    "#         )\n",
    "\n",
    "#         # drop scores and transform model's internal elelemnt category to element_uid for every prediction\n",
    "#         # also convert np.uint64 to int so it could be json serialized later\n",
    "#         als_candidates[user_uid] = [i for i, _ in recs]\n",
    "        \n",
    "    candidates = combine_candidates(\n",
    "        val_users=val_users, \n",
    "        candidates1=already_candidates, \n",
    "        candidates2=val_pred_als\n",
    "    )\n",
    "        \n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_PATH, 'step3_clicks_als.pkl'), 'rb') as f:\n",
    "    als_click_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33987fcf6b0547ada56888645c64feb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8275), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae188b61cd9146efa79c0ab8d43a5c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8275), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26277780a38147afb6633ab595b38a65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8275), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8efc8340e71d4e158958d40a644fb195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8275), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0dd34b5383a4708bc746cb2d0c380fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aea3f6ebced4136aff6e9ce9efd9e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combine_pairs(candidates):\n",
    "    users = []\n",
    "    pictures = []\n",
    "    for key in tqdm(candidates):\n",
    "        users += np.repeat([key], repeats=len(candidates[key])).tolist()\n",
    "        pictures += candidates[key]\n",
    "            \n",
    "    return pd.DataFrame({'user_id': users, 'picture_id': pictures})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edfc236f7d1e47a0b948426dd9af9969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8011), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b81e2f064c464b18af83b22b07a4b1b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8028), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c305039b28b74fab81aec184be4393e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_als_feature(pairs, model, add_factors, mode):\n",
    "    global user_mapping\n",
    "    global picture_mapping\n",
    "    \n",
    "    user_factors = model.user_factors\n",
    "    picture_factors = model.item_factors\n",
    "    \n",
    "    user_ids = pairs['user_id'].map(user_mapping.set_index('old').new).values\n",
    "    picture_ids = pairs['picture_id'].map(picture_mapping.set_index('old').new).values\n",
    "    \n",
    "    scores = np.sum(user_factors[user_ids] * picture_factors[picture_ids], axis=1)\n",
    "    pairs['{}_als_score'.format(mode)] = scores\n",
    "    \n",
    "    if add_factors:\n",
    "        user_factors_df = pd.DataFrame(\n",
    "            user_factors[user_ids], \n",
    "            columns=['user_factor_{}'.format(i) for i in range(user_factors.shape[1])]\n",
    "        )\n",
    "        picture_factors_df = pd.DataFrame(\n",
    "            picture_factors[picture_ids], \n",
    "            columns=['picture_factor_{}'.format(i) for i in range(picture_factors.shape[1])]\n",
    "        )  \n",
    "        \n",
    "        user_picture_factors_df = pd.DataFrame(\n",
    "            np.multiply(user_factors[user_ids], picture_factors[picture_ids], dtype=np.int16), \n",
    "            columns=['user_picture_factor_{}'.format(i) for i in range(model.factors)],\n",
    "        )  \n",
    "        \n",
    "        pairs = pd.concat([pairs, user_factors_df, picture_factors_df, user_picture_factors_df], axis=1)\n",
    "    \n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# del pairs1\n",
    "# del pairs2\n",
    "# del pairs_test\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_clicks['y'] = 1\n",
    "target1 = val_clicks.query('user_id in @val1_users')\n",
    "target2 = val_clicks.query('user_id in @val2_users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates1 = get_als_candidates(\n",
    "    list(val1_users), \n",
    "    train_clicks,\n",
    "    als_click_model, \n",
    "    already_candidates={},\n",
    "    N=2000\n",
    ")\n",
    "pairs1 = get_combine_pairs(candidates=candidates1)\n",
    "pairs1 = generate_als_feature(pairs1, als_click_model, add_factors=False, mode='clicks')\n",
    "\n",
    "cols = ['user_id', 'picture_id', 'y']\n",
    "pairs1 = pairs1.merge(target1[cols], on=['user_id', 'picture_id'], how='left').fillna(0)\n",
    "\n",
    "pairs1.to_hdf(os.path.join(DATA_PATH, 'step4_val1_pairs.h5'), key='step4', mode='w')\n",
    "\n",
    "# del pairs1\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates2 = get_als_candidates(\n",
    "    list(val2_users), \n",
    "    train_clicks,\n",
    "    als_click_model, \n",
    "    already_candidates={},\n",
    "    N=2000\n",
    ")\n",
    "pairs2 = get_combine_pairs(candidates=candidates2)\n",
    "pairs2 = generate_als_feature(pairs2, als_click_model, add_factors=False, mode='clicks')\n",
    "\n",
    "cols = ['user_id', 'picture_id', 'y']\n",
    "pairs2 = pairs2.merge(target2[cols], on=['user_id', 'picture_id'], how='left').fillna(0)\n",
    "\n",
    "pairs2.to_hdf(os.path.join(DATA_PATH, 'step4_val2_pairs.h5'), key='step4', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_test = get_als_candidates(\n",
    "    list(set(test_users['user_id'])), \n",
    "    train_clicks,\n",
    "    als_click_model, \n",
    "    already_candidates={},\n",
    "    N=2000\n",
    ")\n",
    "pairs_test = get_combine_pairs(candidates=candidates_test)\n",
    "pairs_test = generate_als_feature(pairs_test, als_click_model, add_factors=False, mode='clicks')\n",
    "\n",
    "pairs_test.to_hdf(os.path.join(DATA_PATH, 'step4_test_pairs.h5'), key='step4', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.3990635090280146e-05\n",
      "5.2443705388204566e-05\n"
     ]
    }
   ],
   "source": [
    "print (np.sum(pairs1['y']==1) / np.sum(pairs1['y']==0))\n",
    "print (np.sum(pairs2['y']==1) / np.sum(pairs2['y']==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwxrwxrwx 1 root root  74M Jun  1 22:40 step4_test_pairs.h5\r\n",
      "-rwxrwxrwx 1 root root 551M Jun  1 22:39 step4_val1_pairs.h5\r\n",
      "-rwxrwxrwx 1 root root 552M Jun  1 22:40 step4_val2_pairs.h5\r\n"
     ]
    }
   ],
   "source": [
    "!ls -alh data | grep step4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
